{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from typing import Generator, Tuple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "nltk.download(\"stopwords\")\r\n",
    "nltk.download(\"wordnet\")\r\n",
    "nltk.download(\"omw-1.4\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wilat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wilat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\wilat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "stop_words = set(stopwords.words('english'))\r\n",
    "list(stop_words)[:4]\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['each', 'in', 'so', 'hasn']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "START = \"<?xml version='1.0' encoding='utf-8'?><BODY>\"\r\n",
    "END = \"</BODY>\"\r\n",
    "\r\n",
    "DATADIR = \"big_data_project/data\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "train_files = pd.read_csv(\"big_data_project/train.csv\", names=[\"id\", \"file\", \"pos\"], skiprows=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "test_files = pd.read_csv(\"big_data_project/test.csv\", names=[\"id\", \"file\", \"pos\"], skiprows=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_files.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   file  pos\n",
       "0   1  1.xml    0\n",
       "1   2  2.xml    0\n",
       "2   3  3.xml    0\n",
       "3   4  4.xml    0\n",
       "4   5  5.xml    0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "test_files.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20.xml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>47.xml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>57.xml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>66.xml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>88.xml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    file  pos\n",
       "0  20  20.xml  NaN\n",
       "1  47  47.xml  NaN\n",
       "2  57  57.xml  NaN\n",
       "3  66  66.xml  NaN\n",
       "4  88  88.xml  NaN"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def get_files(files: pd.DataFrame) -> Generator[Tuple[str,str], None, None]:\r\n",
    "    for file, pos in zip(files[\"file\"], files[\"pos\"]):\r\n",
    "        with open(f\"{DATADIR}/{file}\", \"r\") as f:\r\n",
    "            content = \" \".join(f.readlines())[len(START):-len(END)]\r\n",
    "        \r\n",
    "        yield content, pos\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "def get_tests(files: pd.DataFrame) -> Generator[Tuple[str,str,str], None, None]:\r\n",
    "    for fid, file in zip(files[\"id\"], files[\"file\"]):\r\n",
    "        with open(f\"{DATADIR}/{file}\", \"r\") as f:\r\n",
    "            content = \" \".join(f.readlines())[len(START):-len(END)]\r\n",
    "        \r\n",
    "        yield fid, file, content\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "files = [e for e in get_files(train_files)]\r\n",
    "files[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Standard Oil Co and BP North America\\n Inc said they plan to form a venture to manage the money market\\n borrowing and investment activities of both companies.\\n     BP North America is a subsidiary of British Petroleum Co\\n Plc &lt;BP>, which also owns a 55 pct interest in Standard Oil.\\n     The venture will be called BP/Standard Financial Trading\\n and will be operated by Standard Oil under the oversight of a\\n joint management committee.\\n \\n  Reuter\\n     ',\n",
       " 0)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "X = [x for x,y in files]\r\n",
    "y = [y for x,y in files]\r\n",
    "\r\n",
    "X = np.array(X)\r\n",
    "y = np.array(y)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "stemmer = WordNetLemmatizer()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def clean_txt(txt: str) -> str:\r\n",
    "    # Remove all the special characters\r\n",
    "    txt = re.sub(r'\\W', ' ', txt)\r\n",
    "    \r\n",
    "    # remove all single characters\r\n",
    "    txt = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)\r\n",
    "    \r\n",
    "    # Remove single characters from the start\r\n",
    "    txt = re.sub(r'\\^[a-zA-Z]\\s+', ' ', txt) \r\n",
    "    \r\n",
    "    # Substituting multiple spaces with single space\r\n",
    "    txt = re.sub(r'\\s+', ' ', txt, flags=re.I)\r\n",
    "    \r\n",
    "    # Removing prefixed 'b'\r\n",
    "    txt = re.sub(r'^b\\s+', '', txt)\r\n",
    "    \r\n",
    "    # Converting to Lowercase\r\n",
    "    txt = txt.lower()\r\n",
    "    \r\n",
    "    # Lemmatization\r\n",
    "    document = txt.split()\r\n",
    "\r\n",
    "    document = [stemmer.lemmatize(w) for w in document]\r\n",
    "    return \" \".join(document)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "Xc = np.array([clean_txt(x) for x in X])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xc, y, test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train data\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "tfidfconverter = TfidfVectorizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "X_train = tfidfconverter.fit_transform(X_train)\r\n",
    "X_test = tfidfconverter.transform(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\r\n",
    "classifier.fit(X_train, y_train)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "y_pred = classifier.predict(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "\r\n",
    "print(confusion_matrix(y_test,y_pred))\r\n",
    "print(classification_report(y_test,y_pred))\r\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[752   8]\n",
      " [ 52 148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       760\n",
      "           1       0.95      0.74      0.83       200\n",
      "\n",
      "    accuracy                           0.94       960\n",
      "   macro avg       0.94      0.86      0.90       960\n",
      "weighted avg       0.94      0.94      0.93       960\n",
      "\n",
      "0.9375\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "tfiles = [e for e in get_tests(test_files)]\r\n",
    "tfiles[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(47,\n",
       " '47.xml',\n",
       " 'inflation\\n plan, initially hailed at home and abroad as the saviour of the\\n economy, is limping towards its first anniversary amid soaring\\n prices, widespread shortages and a foreign payments crisis.\\n     Announced last February 28 the plan froze prices, fixed the\\n value of the new Cruzado currency and ended widespread\\n indexation of the economy in a bid to halt the country\\'s 250\\n pct inflation rate.\\n     But within a year the plan has all but collapsed.\\n     \"The situation now is worse than it was. Although there was\\n inflation, at least the economy worked,\" a leading bank\\n economist said.\\n     The crumbling of the plan has been accompanied by a\\n dramatic reversal in the foreign trade account. In 1984 and\\n 1985 Brazil\\'s annual trade surpluses had been sufficient to\\n cover the 12 billion dlrs needed to service its 109 billion dlr\\n foreign debt.\\n     For the first nine months of 1986 all seemed to be on\\n target for a repeat, with monthly surpluses averaging one\\n billion dlrs. But as exports were diverted and imports\\n increased to avoid further domestic shortages the trade surplus\\n plunged to 211 mln dlrs in October and since then has averaged\\n under 150 mln.\\n  Reuter\\n     ')"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "end_test = [(fid, file, classifier.predict(tfidfconverter.transform([content]))[0]) for fid, file, content in tfiles]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "end_test_df = pd.DataFrame(end_test, columns=[\"id\",\"file\",\"earnings: 0 no/ 1 yes\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "end_test_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file</th>\n",
       "      <th>earnings: 0 no/ 1 yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>47.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>57.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>66.xml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>88.xml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    file  earnings: 0 no/ 1 yes\n",
       "0  20  20.xml                      0\n",
       "1  47  47.xml                      0\n",
       "2  57  57.xml                      0\n",
       "3  66  66.xml                      1\n",
       "4  88  88.xml                      0"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "end_test_df.to_csv(\"big_data_project/output.csv\", index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "df781a511096d3a81d0723c0d57209d194366231e2ac4296d0bfb6094fbd7f01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}